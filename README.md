## ðŸ¤– Classifier Comparison & Ensemble Learning

This project compares the performance of several traditional machine learning classifiers on a dataset, then applies **bagging** and **boosting** techniques to improve their results. The evaluation is based on a variety of metrics including **F1-score**, **accuracy**, **precision**, **recall**, **confusion matrix**, **ROC curve**, and **AUC score**.

---

## ðŸ“Œ Project Goals

- Train and evaluate baseline classifiers:
  - Decision Tree
  - Logistic Regression
  - K-Nearest Neighbors
  - Gaussian Naive Bayes
- Compare model performance using robust evaluation metrics
- Apply:
  - **Bagging** (e.g. Random Forest, BaggingClassifier)
  - **Boosting** (e.g. AdaBoost, GradientBoosting)

## ðŸ›  Tech Stack

- **Python 3**
- **Scikit-learn** â€“ ML models and metrics
- **Pandas / NumPy** â€“ Data manipulation
- **Matplotlib / Seaborn** â€“ Visualization
- **Scikit-plot / Yellowbrick** (optional) â€“ Advanced evaluation plots

---
